{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all necessary libraries\n",
    "from tensorflow.keras.models import Sequential    #For initialising the model\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from numpy import loadtxt\n",
    "from sklearn import preprocessing, model_selection as ms  #for splitting data into Training, Cross - Validating, and Testing parts\n",
    "import matplotlib.pyplot as plt  #for plotting training and cross validation accuracies vs epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net_model(h_layers, neurons):        #returns the model with desired parameters\n",
    "    model = Sequential() #initialise the model\n",
    "    \n",
    "    for i in range( h_layers ):  #add all hidden layers\n",
    "        model.add( Dense( units = neurons, activation = 'relu' )) #can choose custom activation function\n",
    "        \n",
    "    model.add( Dense( units = 1, activation = 'sigmoid' ))  #add an output layer\n",
    "\n",
    "    model.compile( optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])  #define optimizer and loss functions as well as required metrics\n",
    "    #'binary_crossentropy' as it is a two-class problem. Use 'categorical_crossentropy' for multi-class problems. \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model\n",
    "model = neural_net_model(2, 5) #hyper-parameters\n",
    "\n",
    "#Ensure to convert your dataset to numpy arrays and store the data in X_data and y_data\n",
    "X_data = [] #list that contains all features as numpy arrays\n",
    "y_data = [] #list for holding the labels corresponding to the respective rows\n",
    "\n",
    "#training the model\n",
    "history = model.fit(X_data, y_data, validation_split=0.33, epochs=150, batch_size=10) #hyper-parameters, using 1/3rd of data for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc = 'best')\n",
    "plt.show()\n",
    "\n",
    "#plot history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make class predictions with the model \n",
    "#calling the predict_classes() function on the model to predict crisp classes directly\n",
    "predictions = model.predict_classes(X_data)\n",
    "\n",
    "#'predictions' can be used to generate a new submission.csv "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
